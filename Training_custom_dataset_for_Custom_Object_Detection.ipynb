{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mushtariy00/Mushtariy00/blob/main/Training_custom_dataset_for_Custom_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHvcyrGUF-pu"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJEzDG6DK2Q"
      },
      "source": [
        "# Train a custom object detection model with TensorFlow Lite Model Maker\n",
        "\n",
        "In this colab notebook, we use the TensorFlow Lite Model Maker to train a custom object detection model and use it on Rapberry Pi.\n",
        "We use exsisting trained model to train our model with our custom dataset. This method is called  *transfer learning*. Retraining a exsisting model with your own custom dataset reduces the amount of training data and will shorten the training time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYjtwRZGBOI"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "### Install the required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "35BJmtVpAP_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0602cf-0128-46ea-b1a6-5f9ce2b7d58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 13.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 43.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 10.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 52 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 49.6 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install -q tflite-support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prQ86DdtD317"
      },
      "source": [
        "### Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l4QQTXHHATDS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "from tflite_support import metadata\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect google drive to Colab then you can easily use datasets in your goole drive. "
      ],
      "metadata": {
        "id": "H9NPr2AOFGus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "6cc61bee-112d-4694-bdcf-888df075c647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip the dataset file and extract the data"
      ],
      "metadata": {
        "id": "4NuTLICKuH9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/My\\ Drive/object_detection/data/PE.zip"
      ],
      "metadata": {
        "id": "c397be4ZMF74"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxh3KInCFeB-"
      },
      "source": [
        "## Train the object detection model\n",
        "\n",
        "### Step 1: Load the dataset\n",
        "\n",
        "* Images in `train_data` is used to train the custom object detection model.\n",
        "* Images in `val_data` is used to check if the model can generalize well to new images that it hasn't seen before."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'PE/train',\n",
        "    'PE/train',\n",
        "    ['pig', 'elephant']\n",
        ")\n",
        "\n",
        "val_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'PE/validate',\n",
        "    'PE/validate',\n",
        "    ['pig', 'elephant']\n",
        ")"
      ],
      "metadata": {
        "id": "ZRLRkvBwJ8jh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNRhB8N7GHXj"
      },
      "source": [
        "### Step 2: Select a model architecture\n",
        "\n",
        "EfficientDet-Lite[0-4] are a family of mobile/IoT-friendly object detection models derived from the [EfficientDet](https://arxiv.org/abs/1911.09070) architecture.\n",
        "\n",
        "Here is the performance of each EfficientDet-Lite models compared to each others.\n",
        "\n",
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 146           | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 259           | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 396           | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 716           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 1886          | 41.96%               |\n",
        "\n",
        "\n",
        "In this notebook, we use EfficientDet-Lite0 to train our model. You can choose other model architectures depending on whether speed or accuracy is more important to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GZOojrDHAY1J"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aeDU4mIM4ft"
      },
      "source": [
        "### Step 3: Train the TensorFlow model with the training data.\n",
        "\n",
        "* Set `epochs = 50`, our custom model will be trained by using the same custom dataset 50 times over and over. \n",
        "* Set `batch_size = 10` here so you will see that it takes 18 steps to go through the 180 images in the training dataset.\n",
        "* Set `train_whole_model=True` to retrain the whole model instead of just training the head layer to improve accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MClfpsJAfda",
        "outputId": "fbd09398-5609-4958-d926-107cd3b7572d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 70s 1s/step - det_loss: 1.6944 - cls_loss: 1.1278 - box_loss: 0.0113 - reg_l2_loss: 0.0629 - loss: 1.7574 - learning_rate: 0.0102 - gradient_norm: 1.3756 - val_det_loss: 1.4489 - val_cls_loss: 1.0186 - val_box_loss: 0.0086 - val_reg_l2_loss: 0.0629 - val_loss: 1.5118\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 16s 877ms/step - det_loss: 1.2556 - cls_loss: 0.8592 - box_loss: 0.0079 - reg_l2_loss: 0.0630 - loss: 1.3185 - learning_rate: 0.0125 - gradient_norm: 2.0625 - val_det_loss: 1.4003 - val_cls_loss: 1.0971 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0630 - val_loss: 1.4633\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 16s 897ms/step - det_loss: 0.8078 - cls_loss: 0.5440 - box_loss: 0.0053 - reg_l2_loss: 0.0630 - loss: 0.8708 - learning_rate: 0.0124 - gradient_norm: 2.0619 - val_det_loss: 0.8604 - val_cls_loss: 0.4959 - val_box_loss: 0.0073 - val_reg_l2_loss: 0.0630 - val_loss: 0.9234\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 16s 923ms/step - det_loss: 0.6165 - cls_loss: 0.4080 - box_loss: 0.0042 - reg_l2_loss: 0.0630 - loss: 0.6795 - learning_rate: 0.0123 - gradient_norm: 2.3891 - val_det_loss: 0.8006 - val_cls_loss: 0.4630 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0630 - val_loss: 0.8636\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 24s 1s/step - det_loss: 0.5006 - cls_loss: 0.3311 - box_loss: 0.0034 - reg_l2_loss: 0.0631 - loss: 0.5637 - learning_rate: 0.0122 - gradient_norm: 2.3850 - val_det_loss: 0.7060 - val_cls_loss: 0.4144 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0631 - val_loss: 0.7690\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 16s 887ms/step - det_loss: 0.4311 - cls_loss: 0.2851 - box_loss: 0.0029 - reg_l2_loss: 0.0631 - loss: 0.4942 - learning_rate: 0.0121 - gradient_norm: 2.4666 - val_det_loss: 0.7434 - val_cls_loss: 0.5351 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0631 - val_loss: 0.8065\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 16s 906ms/step - det_loss: 0.3593 - cls_loss: 0.2482 - box_loss: 0.0022 - reg_l2_loss: 0.0631 - loss: 0.4225 - learning_rate: 0.0120 - gradient_norm: 2.3631 - val_det_loss: 0.5355 - val_cls_loss: 0.3654 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0631 - val_loss: 0.5986\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 16s 884ms/step - det_loss: 0.3532 - cls_loss: 0.2470 - box_loss: 0.0021 - reg_l2_loss: 0.0631 - loss: 0.4163 - learning_rate: 0.0118 - gradient_norm: 2.4333 - val_det_loss: 0.4525 - val_cls_loss: 0.2466 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0632 - val_loss: 0.5157\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 15s 880ms/step - det_loss: 0.3163 - cls_loss: 0.2229 - box_loss: 0.0019 - reg_l2_loss: 0.0632 - loss: 0.3795 - learning_rate: 0.0116 - gradient_norm: 2.2117 - val_det_loss: 0.3509 - val_cls_loss: 0.2171 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0632 - val_loss: 0.4140\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.2782 - cls_loss: 0.1986 - box_loss: 0.0016 - reg_l2_loss: 0.0632 - loss: 0.3414 - learning_rate: 0.0114 - gradient_norm: 1.9075 - val_det_loss: 0.4588 - val_cls_loss: 0.3718 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0632 - val_loss: 0.5219\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 16s 905ms/step - det_loss: 0.2633 - cls_loss: 0.1813 - box_loss: 0.0016 - reg_l2_loss: 0.0632 - loss: 0.3265 - learning_rate: 0.0111 - gradient_norm: 1.6883 - val_det_loss: 0.3200 - val_cls_loss: 0.2494 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0632 - val_loss: 0.3832\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 15s 877ms/step - det_loss: 0.2572 - cls_loss: 0.1759 - box_loss: 0.0016 - reg_l2_loss: 0.0632 - loss: 0.3204 - learning_rate: 0.0109 - gradient_norm: 1.7878 - val_det_loss: 0.1854 - val_cls_loss: 0.1416 - val_box_loss: 8.7686e-04 - val_reg_l2_loss: 0.0632 - val_loss: 0.2486\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 15s 883ms/step - det_loss: 0.2433 - cls_loss: 0.1756 - box_loss: 0.0014 - reg_l2_loss: 0.0632 - loss: 0.3065 - learning_rate: 0.0106 - gradient_norm: 2.0411 - val_det_loss: 0.4465 - val_cls_loss: 0.3959 - val_box_loss: 0.0010 - val_reg_l2_loss: 0.0632 - val_loss: 0.5097\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 16s 885ms/step - det_loss: 0.2515 - cls_loss: 0.1851 - box_loss: 0.0013 - reg_l2_loss: 0.0632 - loss: 0.3148 - learning_rate: 0.0103 - gradient_norm: 2.7335 - val_det_loss: 0.2180 - val_cls_loss: 0.1541 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0633 - val_loss: 0.2813\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.2361 - cls_loss: 0.1699 - box_loss: 0.0013 - reg_l2_loss: 0.0633 - loss: 0.2994 - learning_rate: 0.0100 - gradient_norm: 2.3933 - val_det_loss: 0.4672 - val_cls_loss: 0.3601 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0633 - val_loss: 0.5305\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 16s 918ms/step - det_loss: 0.2344 - cls_loss: 0.1649 - box_loss: 0.0014 - reg_l2_loss: 0.0633 - loss: 0.2977 - learning_rate: 0.0097 - gradient_norm: 2.0243 - val_det_loss: 0.3135 - val_cls_loss: 0.2100 - val_box_loss: 0.0021 - val_reg_l2_loss: 0.0633 - val_loss: 0.3768\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 15s 877ms/step - det_loss: 0.2224 - cls_loss: 0.1512 - box_loss: 0.0014 - reg_l2_loss: 0.0633 - loss: 0.2857 - learning_rate: 0.0093 - gradient_norm: 2.3033 - val_det_loss: 0.4841 - val_cls_loss: 0.4255 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0633 - val_loss: 0.5474\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 16s 883ms/step - det_loss: 0.1958 - cls_loss: 0.1401 - box_loss: 0.0011 - reg_l2_loss: 0.0633 - loss: 0.2591 - learning_rate: 0.0090 - gradient_norm: 1.7196 - val_det_loss: 0.1732 - val_cls_loss: 0.1312 - val_box_loss: 8.4080e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2365\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 16s 891ms/step - det_loss: 0.1953 - cls_loss: 0.1437 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2586 - learning_rate: 0.0086 - gradient_norm: 1.7021 - val_det_loss: 0.2029 - val_cls_loss: 0.1347 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0633 - val_loss: 0.2662\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1868 - cls_loss: 0.1376 - box_loss: 9.8476e-04 - reg_l2_loss: 0.0633 - loss: 0.2502 - learning_rate: 0.0082 - gradient_norm: 1.5077 - val_det_loss: 0.1692 - val_cls_loss: 0.1223 - val_box_loss: 9.3811e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2325\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 16s 889ms/step - det_loss: 0.1908 - cls_loss: 0.1399 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2541 - learning_rate: 0.0078 - gradient_norm: 1.6095 - val_det_loss: 0.1498 - val_cls_loss: 0.1127 - val_box_loss: 7.4098e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2131\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 16s 909ms/step - det_loss: 0.1818 - cls_loss: 0.1325 - box_loss: 9.8536e-04 - reg_l2_loss: 0.0633 - loss: 0.2451 - learning_rate: 0.0074 - gradient_norm: 1.5976 - val_det_loss: 0.1310 - val_cls_loss: 0.0988 - val_box_loss: 6.4402e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1943\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 16s 887ms/step - det_loss: 0.1685 - cls_loss: 0.1212 - box_loss: 9.4575e-04 - reg_l2_loss: 0.0633 - loss: 0.2318 - learning_rate: 0.0071 - gradient_norm: 1.4807 - val_det_loss: 0.1278 - val_cls_loss: 0.1022 - val_box_loss: 5.1218e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1912\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 17s 941ms/step - det_loss: 0.1532 - cls_loss: 0.1144 - box_loss: 7.7441e-04 - reg_l2_loss: 0.0633 - loss: 0.2165 - learning_rate: 0.0067 - gradient_norm: 1.3750 - val_det_loss: 0.1328 - val_cls_loss: 0.1004 - val_box_loss: 6.4745e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1961\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1572 - cls_loss: 0.1191 - box_loss: 7.6153e-04 - reg_l2_loss: 0.0633 - loss: 0.2205 - learning_rate: 0.0063 - gradient_norm: 1.4956 - val_det_loss: 0.1228 - val_cls_loss: 0.0996 - val_box_loss: 4.6398e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1861\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 16s 915ms/step - det_loss: 0.1506 - cls_loss: 0.1128 - box_loss: 7.5654e-04 - reg_l2_loss: 0.0633 - loss: 0.2139 - learning_rate: 0.0059 - gradient_norm: 1.2068 - val_det_loss: 0.1186 - val_cls_loss: 0.0939 - val_box_loss: 4.9462e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1819\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 16s 898ms/step - det_loss: 0.1790 - cls_loss: 0.1326 - box_loss: 9.2784e-04 - reg_l2_loss: 0.0633 - loss: 0.2423 - learning_rate: 0.0055 - gradient_norm: 1.7698 - val_det_loss: 0.1235 - val_cls_loss: 0.0993 - val_box_loss: 4.8462e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1869\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 16s 937ms/step - det_loss: 0.1573 - cls_loss: 0.1167 - box_loss: 8.1271e-04 - reg_l2_loss: 0.0633 - loss: 0.2206 - learning_rate: 0.0051 - gradient_norm: 1.4262 - val_det_loss: 0.1496 - val_cls_loss: 0.1025 - val_box_loss: 9.4252e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2130\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 16s 905ms/step - det_loss: 0.1583 - cls_loss: 0.1155 - box_loss: 8.5553e-04 - reg_l2_loss: 0.0633 - loss: 0.2216 - learning_rate: 0.0047 - gradient_norm: 1.3485 - val_det_loss: 0.1241 - val_cls_loss: 0.0949 - val_box_loss: 5.8500e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1875\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1467 - cls_loss: 0.1109 - box_loss: 7.1536e-04 - reg_l2_loss: 0.0633 - loss: 0.2100 - learning_rate: 0.0043 - gradient_norm: 1.2319 - val_det_loss: 0.1190 - val_cls_loss: 0.0914 - val_box_loss: 5.5168e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1823\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 16s 894ms/step - det_loss: 0.1364 - cls_loss: 0.1026 - box_loss: 6.7737e-04 - reg_l2_loss: 0.0633 - loss: 0.1998 - learning_rate: 0.0039 - gradient_norm: 1.2533 - val_det_loss: 0.1021 - val_cls_loss: 0.0822 - val_box_loss: 3.9830e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1655\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 16s 921ms/step - det_loss: 0.1362 - cls_loss: 0.1029 - box_loss: 6.6604e-04 - reg_l2_loss: 0.0633 - loss: 0.1995 - learning_rate: 0.0035 - gradient_norm: 1.0871 - val_det_loss: 0.1079 - val_cls_loss: 0.0884 - val_box_loss: 3.9062e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1713\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 15s 876ms/step - det_loss: 0.1403 - cls_loss: 0.1071 - box_loss: 6.6528e-04 - reg_l2_loss: 0.0633 - loss: 0.2037 - learning_rate: 0.0032 - gradient_norm: 1.1675 - val_det_loss: 0.1028 - val_cls_loss: 0.0820 - val_box_loss: 4.1598e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1661\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 15s 873ms/step - det_loss: 0.1502 - cls_loss: 0.1139 - box_loss: 7.2584e-04 - reg_l2_loss: 0.0633 - loss: 0.2135 - learning_rate: 0.0028 - gradient_norm: 1.6094 - val_det_loss: 0.0974 - val_cls_loss: 0.0815 - val_box_loss: 3.1868e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1608\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 20s 1s/step - det_loss: 0.1471 - cls_loss: 0.1088 - box_loss: 7.6579e-04 - reg_l2_loss: 0.0633 - loss: 0.2104 - learning_rate: 0.0025 - gradient_norm: 1.2443 - val_det_loss: 0.1014 - val_cls_loss: 0.0836 - val_box_loss: 3.5742e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1648\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 16s 913ms/step - det_loss: 0.1361 - cls_loss: 0.1039 - box_loss: 6.4388e-04 - reg_l2_loss: 0.0633 - loss: 0.1994 - learning_rate: 0.0022 - gradient_norm: 1.1964 - val_det_loss: 0.0976 - val_cls_loss: 0.0796 - val_box_loss: 3.6013e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1610\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 15s 880ms/step - det_loss: 0.1324 - cls_loss: 0.1058 - box_loss: 5.3251e-04 - reg_l2_loss: 0.0633 - loss: 0.1957 - learning_rate: 0.0019 - gradient_norm: 1.1237 - val_det_loss: 0.0936 - val_cls_loss: 0.0796 - val_box_loss: 2.7995e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1569\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 15s 856ms/step - det_loss: 0.1337 - cls_loss: 0.1036 - box_loss: 6.0263e-04 - reg_l2_loss: 0.0633 - loss: 0.1970 - learning_rate: 0.0016 - gradient_norm: 1.1253 - val_det_loss: 0.0979 - val_cls_loss: 0.0822 - val_box_loss: 3.1469e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1613\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 15s 861ms/step - det_loss: 0.1297 - cls_loss: 0.1007 - box_loss: 5.7956e-04 - reg_l2_loss: 0.0633 - loss: 0.1930 - learning_rate: 0.0014 - gradient_norm: 1.1466 - val_det_loss: 0.1004 - val_cls_loss: 0.0820 - val_box_loss: 3.6858e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1637\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1284 - cls_loss: 0.0994 - box_loss: 5.8026e-04 - reg_l2_loss: 0.0633 - loss: 0.1917 - learning_rate: 0.0011 - gradient_norm: 1.0169 - val_det_loss: 0.0925 - val_cls_loss: 0.0789 - val_box_loss: 2.7118e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1558\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 15s 854ms/step - det_loss: 0.1304 - cls_loss: 0.1014 - box_loss: 5.7896e-04 - reg_l2_loss: 0.0633 - loss: 0.1937 - learning_rate: 9.0695e-04 - gradient_norm: 1.0142 - val_det_loss: 0.0988 - val_cls_loss: 0.0812 - val_box_loss: 3.5345e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1622\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 15s 865ms/step - det_loss: 0.1279 - cls_loss: 0.1004 - box_loss: 5.4961e-04 - reg_l2_loss: 0.0633 - loss: 0.1912 - learning_rate: 7.1032e-04 - gradient_norm: 1.0747 - val_det_loss: 0.0982 - val_cls_loss: 0.0819 - val_box_loss: 3.2613e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1615\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 15s 875ms/step - det_loss: 0.1261 - cls_loss: 0.1009 - box_loss: 5.0431e-04 - reg_l2_loss: 0.0633 - loss: 0.1894 - learning_rate: 5.3645e-04 - gradient_norm: 1.0152 - val_det_loss: 0.0953 - val_cls_loss: 0.0798 - val_box_loss: 3.0903e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1586\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 15s 852ms/step - det_loss: 0.1334 - cls_loss: 0.1015 - box_loss: 6.3672e-04 - reg_l2_loss: 0.0633 - loss: 0.1967 - learning_rate: 3.8606e-04 - gradient_norm: 1.1769 - val_det_loss: 0.0965 - val_cls_loss: 0.0798 - val_box_loss: 3.3374e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1598\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1325 - cls_loss: 0.1029 - box_loss: 5.9132e-04 - reg_l2_loss: 0.0633 - loss: 0.1958 - learning_rate: 2.5977e-04 - gradient_norm: 1.1646 - val_det_loss: 0.0956 - val_cls_loss: 0.0796 - val_box_loss: 3.1925e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1589\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 15s 876ms/step - det_loss: 0.1305 - cls_loss: 0.1011 - box_loss: 5.8805e-04 - reg_l2_loss: 0.0633 - loss: 0.1938 - learning_rate: 1.5809e-04 - gradient_norm: 1.1922 - val_det_loss: 0.0944 - val_cls_loss: 0.0790 - val_box_loss: 3.0792e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1577\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 15s 872ms/step - det_loss: 0.1351 - cls_loss: 0.1044 - box_loss: 6.1502e-04 - reg_l2_loss: 0.0633 - loss: 0.1984 - learning_rate: 8.1440e-05 - gradient_norm: 1.1213 - val_det_loss: 0.0944 - val_cls_loss: 0.0788 - val_box_loss: 3.1172e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1578\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 15s 870ms/step - det_loss: 0.1287 - cls_loss: 0.1010 - box_loss: 5.5431e-04 - reg_l2_loss: 0.0633 - loss: 0.1920 - learning_rate: 3.0141e-05 - gradient_norm: 1.1304 - val_det_loss: 0.0942 - val_cls_loss: 0.0787 - val_box_loss: 3.1035e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1575\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 16s 895ms/step - det_loss: 0.1355 - cls_loss: 0.1045 - box_loss: 6.1917e-04 - reg_l2_loss: 0.0633 - loss: 0.1988 - learning_rate: 4.4020e-06 - gradient_norm: 1.1103 - val_det_loss: 0.0946 - val_cls_loss: 0.0788 - val_box_loss: 3.1464e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1579\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 18s 1s/step - det_loss: 0.1257 - cls_loss: 0.0994 - box_loss: 5.2628e-04 - reg_l2_loss: 0.0633 - loss: 0.1891 - learning_rate: 4.3269e-06 - gradient_norm: 1.1980 - val_det_loss: 0.0943 - val_cls_loss: 0.0787 - val_box_loss: 3.1292e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1576\n"
          ]
        }
      ],
      "source": [
        "model = object_detector.create(train_data, model_spec=spec, batch_size=10, train_whole_model=True, epochs=50, validation_data=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4hKeerMmh4"
      },
      "source": [
        "### Step 4. Evaluate the model with the validation data.\n",
        "\n",
        "After training the object detection model using the images in the training dataset, we use the images in the validation dataset to evaluate how the model performs against new data it has never seen before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqEpcYwAg8L",
        "outputId": "638702ae-80fe-44e7-bee7-1ce0c56681b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - 9s 9s/step\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.9370231,\n",
              " 'AP50': 1.0,\n",
              " 'AP75': 1.0,\n",
              " 'AP_/elephant': 0.9241915,\n",
              " 'AP_/pig': 0.9498548,\n",
              " 'APl': 0.9370493,\n",
              " 'APm': -1.0,\n",
              " 'APs': -1.0,\n",
              " 'ARl': 0.965625,\n",
              " 'ARm': -1.0,\n",
              " 'ARmax1': 0.946875,\n",
              " 'ARmax10': 0.965625,\n",
              " 'ARmax100': 0.965625,\n",
              " 'ARs': -1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.evaluate(val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARVYk9rGLIl"
      },
      "source": [
        "### Step 5: Export as a TensorFlow Lite model.\n",
        "\n",
        "Export the trained object detection model to the TensorFlow Lite format by specifying which folder you want to export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_u3eFxoBAiqE"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='my_model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the TensorFlow Lite model\n",
        "Download the TFLite model to your local computer to use on Raspberry Pi for detecting your custom obejects.\n"
      ],
      "metadata": {
        "id": "7m9w2nOEJcqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v7zgUkdOUUnD",
        "outputId": "ecd28f03-dba3-44be-b034-2b8d5a76149e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_98d09789-6518-4fe7-9645-22fc1347b918\", \"my_model.tflite\", 4444719)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('my_model.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Training custom dataset for Custom Object Detection ",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}